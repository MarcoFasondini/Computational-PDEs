{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "__Applied Complex Analysis (2021)__\n\n# Lecture 18: Orthogonal polynomials\n\n\nWe now introduce orthogonal polynomials (OPs). These are __fundamental__ for computational mathematics, with applications in\n1. Function approximation\n2. Quadrature (calculating integrals)\n2. Solving differential equations\n3. Spectral analysis of Schrödinger operators\n\nWe will investigate the properties of _general_ OPs, in this lecture:\n\n1. Definition of orthogonal polynomials\n2. Three-term recurrence relationships\n3. Function approximation with orthogonal polynomials\n2. Construction of orthogonal polynomials via Gram–Schmidt process\n\n\n\n## Definition of orthogonal polynomials\n\nLet $p_0(x),p_1(x),p_2(x),…$ be a sequence of polynomials such that $p_n(x)$ is exactly of degree $n$, that is,\n$$\np_n(x) = k_n x^n + O(x^{n-1})\n$$\nwhere $k_n \\neq 0$.\n\nLet $w(x)$ be a continuous weight function on a (possibly infinite) interval $(a,b)$: that is $w(x) \\geq 0$ for all $a < x < b$.\nThis induces an inner product\n$$\n\\ip<f,g> := \\int_a^b f(x) g(x) w(x) \\dx\n$$\nWe say that $\\{p_0, p_1,\\ldots\\}$ are _orthogonal with respect to the weight $w$_ if\n$$\n\\ip<p_n,p_m> = 0\\qqfor n \\neq m.\n$$\nBecause $w$ is continuous, we have\n$$\n\\norm{p_n}^2 = \\ip<p_n,p_n> > 0 .\n$$\n\nOrthogonal polymomials are not unique: we can multiply each $p_n$ by a different nonzero constant $\\tilde p_n(x) = c_n p_n(x)$, and\n$\\tilde p_n$ will be orthogonal w.r.t. $w$.  However, if we specify $k_n$, this is sufficient to uniquely define them:\n\n**Proposition (Uniqueness of OPs I)** Given a non-zero $k_n$, there is a unique polynomial $p_n$ orthogonal w.r.t. $w$\nto all lower degree polynomials.\n\n**Proof** Suppose $r_n(x) = k_n x^n + O(x^{n-1})$ is another  OP w.r.t. $w$. We want to show $p_n - r_n$ is zero.\nBut this is a polynomial of degree $<n$, hence\n$$\np_n(x) - r_n(x) = \\sum_{k=0}^{n-1} c_k p_k(x)\n$$\nBut we have for $k \\leq n-1$\n$$\n\\ip<p_k,p_k> c_k = \\ip<p_n - r_n, p_k> = \\ip<p_n,p_k> - \\ip<r_n, p_k> = 0 - 0 = 0\n$$\nwhich shows all $c_k$ are zero.\n\n■\n\n**Corollary (Uniqueness of OPs I)** If $q_n$ and $p_n$ are orthogonal w.r.t. $w$ to all lower degree polynomials,\nthen $q_n(x) = C p_n(x)$ for some constant $C$.\n\n### Monic orthogonal polynomials\n\nIf $k_n = 1$, that is,\n$$\np_n(x) = x^n + O(x^{n-1})\n$$\nthen we refer to the orthogonal polynomials as monic.\n\nMonic OPs are unique as we have specified $k_n$.\n\n### Orthonormal polynomials\n\nIf  $\\norm{p_n} = 1$, then we refer to the orthogonal polynomials as orthonormal w.r.t. $w$.\nWe will usually use $q_n$ when they are orthonormal.   Note it's not unique: we can multiply by $\\pm 1$ without changing the norm.\n\n\n**Remark** The classical OPs are neither monic nor orthonormal (apart from one case). Many people make the mistake of using\northonormal polynomials for computations. But there is a good reason to use classical OPs: their properties result in rational formulae,\nwhereas orthonormal polynomials require square roots. This makes a performance difference.\n\n## Function approximation with orthogonal polynomials\n\nA basic usage of orthogonal polynomials is for polynomial approximation.\nSuppose $f(x)$ is a degree $n-1$ polynomial. Since $\\{p_0(x),\\ldots,p_{n-1}(x)\\}$ span all degree $n-1$ polynomials, we know that\n$$\nf(x) = \\sum_{k=0}^{n-1} f_k p_k(x)\n$$\nwhere\n$$\nf_k = {\\ip<f, p_k> \\over \\ip<p_k,p_k>}\n$$\n\n\nSometimes, we want to incorporate the weight into the approximation. This is typically one of two forms, depending on the application:\n$$\nf(x) = w(x) \\sum_{k=0}^\\infty f_k p_k(x)\n$$\nor\n$$\n        f(x) = \\sqrt{w(x)} \\sum_{k=0}^\\infty f_k p_k(x)\n$$\nThe $w(x)p_k(x)$ or $\\sqrt{w(x)}p_k(x)$ are called weighted polynomials.\n\n\n\n## Jacobi operators and three-term recurrences for general orthogonal polynomials\n### Three-term recurrence relationships\n\n\nA central theme: if you know the Jacobi operator / three-term recurrence, you know the polynomials.\nThis is the __best__ way to evaluate expansions in orthogonal polynomials: even for cases where we have explicit\nformulae (e.g. Chebyshev polynomials $T_n(x) = \\cos n \\acos x$),\nusing the recurrence avoids evaluating trigonometric functions.\n\nEvery family of orthogonal polynomials has a three-term recurrence relationship:\n\n**Theorem (three-term recurrence)** Suppose $\\{p_n(x)\\}$ are a family of orthogonal polynomials w.r.t. a weight $w(x)$.\nThen there exists constants $a_n$, $b_n \\neq 0$ and $c_n$ such that\n$$\n\\begin{align*}\nx p_0(x) = a_0 p_0(x) + b_0 p_1(x) \\\\\nx p_n(x) = c_n p_{n-1}(x) + a_n p_n(x) + b_n p_{n+1}(x)\n\\end{align*}\n$$\n\n**Proof**\nThe first part follows since $p_0(x)$ and $p_1(x)$ span all degree 1 polynomials.\n\nThe second part follows essentially because multiplication by $x$ is \"self-adjoint\", that is,\n$$\n\\ip<x f, g> = \\int_a^b x f(x) g(x) w(x) \\dx = \\ip<f, x g>\n$$\nTherefore, if $f_m$ is a degree $m < n-1$ polynomial, we have\n$$\n\\ip<x p_n, f_m> = \\ip<p_n, x f_m> = 0.\n$$\nIn particular, if we write\n$$\nx p_n(x) = \\sum_{k=0}^{n+1} C_k p_k(x)\n$$\nthen\n$$\nC_k = {\\ip< x p_n, p_k> \\over \\norm{p_k}^2} = 0\n$$\nif $k < n-1$.\n\n■\n\n\nMonic polynomials clearly have $b_n = 1$.  Orthonormal polynomials have an even simpler form:\n\n**Theorem (orthonormal three-term recurrence)** Suppose $\\{q_n(x)\\}$ are a family of orthonormal polynomials w.r.t. a weight $w(x)$.\nThen there exists constants $a_n$ and $b_n$ such that\n$$\n\\begin{align*}\nx q_0(x) = a_0 q_0(x)  + b_0 q_1(x)\\\\\nx q_n(x) = b_{n-1} q_{n-1}(x) + a_n q_n(x) + b_{n} q_{n+1}(x)\n\\end{align*}\n$$\n\n**Proof**\nFollows again by self-adjointness of multiplication by $x$:\n$$\nc_n = \\ip<x q_n, q_{n-1}> = \\ip<q_n, x q_{n-1}> = \\ip<x q_{n-1}, q_n> = b_{n-1}\n$$\n■\n\n\n**Corollary (symmetric three-term recurrence implies orthonormality)** Suppose $\\{p_n(x)\\}$ are a family of orthogonal polynomials\nw.r.t. a weight $w(x)$ such that\n$$\n\\begin{align*}\nx p_0(x) = a_0 p_0(x)  + b_0 p_1(x)\\\\\nx p_n(x) = b_{n-1} p_{n-1}(x) + a_n p_n(x) + b_{n} p_{n+1}(x)\n\\end{align*}\n$$\nwith $b_n \\neq 0$. Suppose further that $\\norm{p_0} = 1$. Then $p_n$ must be orthonormal.\n\n**Proof** This follows from\n$$\nb_n = {\\ip<x p_n,p_{n+1}> \\over \\norm{p_{n+1}}^2} = {\\ip<x p_{n+1}, p_n> \\over \\norm{p_{n+1}}^2} = b_n   {\\norm{p_n}^2 \\over \\norm{p_{n+1}}^2 }\n$$\nwhich implies\n$$\n\\norm{p_{n+1}}^2 = \\norm{p_n}^2 = \\cdots = \\norm{p_0}^2 = 1\n$$\n■\n\n**Remark** We can scale $w(x)$ by a constant without changing the orthogonality properties, hence we can make $\\|p_0\\| = 1$ by changing the weight.\n\n**Remark** This is beyond the scope of this course, but satisfying a three-term recurrence like this such that coefficients\nare bounded with $p_0(x) = 1$ is sufficient to show that there exists a $w(x)$ (or more accurately, a Borel measure)\nsuch that $p_n(x)$ are orthogonal w.r.t. $w$. The relationship between the coefficients $a_n,b_n$ and the $w(x)$ is\nan object of study in spectral theory, particularly when the coefficients are periodic, quasi-periodic or random.\n\n## Jacobi operators and multiplication by $x$\n\nWe can rewrite the three-term recurrence as\n$$\nx \\begin{pmatrix} p_0(x) \\cr p_1(x) \\cr p_2(x) \\cr \\vdots \\end{pmatrix} = J\\begin{pmatrix} p_0(x) \\cr p_1(x) \\cr p_2(x) \\cr \\vdots \\end{pmatrix}\n$$\nwhere $J$ is a Jacobi operator, an infinite-dimensional tridiagonal matrix:\n$$\nJ = \\begin{pmatrix}\na_0 & b_0 \\cr\nc_1 & a_1 & b_1 \\cr\n& c_2 & a_2 & b_2 \\cr\n&& c_3 & a_3 & \\ddots \\cr\n&&&\\ddots & \\ddots\n\\end{pmatrix}\n$$\n\nWhen the polynomials are monic, we have $1$ on the superdiagonal.  When we have an orthonormal basis, then $J$ is symmetric:\n$$\nJ = \\begin{pmatrix}\na_0 & b_0 \\cr\nb_0 & a_1 & b_1 \\cr\n& b_1 & a_2 & b_2 \\cr\n&& b_2 & a_3 & \\ddots \\cr\n&&&\\ddots & \\ddots\n\\end{pmatrix}\n$$\n\n\nGiven a polynomial expansion, $J$ tells us how to multiply by $x$ in coefficient space, that is, if\n$$\nf(x) = \\sum_{k=0}^\\infty f_k p_k(x) =   (p_0(x) ,  p_1(x) , \\ldots ) \\begin{pmatrix}f_0\\\\ f_1\\\\f_2\\\\\\vdots\\end{pmatrix}\n$$\nthen (provided the relevant sums converge absolutely and uniformly)\n$$\nx f(x) = x (p_0(x) ,  p_1(x) , \\ldots ) \\begin{pmatrix}f_0\\\\ f_1\\\\f_2\\\\\\vdots\\end{pmatrix} =\n    \\left(J \\begin{pmatrix} p_0(x) \\cr p_1(x) \\cr p_2(x) \\cr \\vdots \\end{pmatrix}\\right)^\\top  \\begin{pmatrix}f_0\\\\ f_1\\\\f_2\\\\\\vdots\\end{pmatrix} = (p_0(x) ,  p_1(x) , \\ldots ) X \\begin{pmatrix}f_0\\\\ f_1\\\\f_2\\\\\\vdots\\end{pmatrix}\n$$\nwhere $X := J^\\top$.\n\n\n\n### Evaluating polynomials\n\n\nWe can use the three-term recurrence to construct the polynomials.\nOne way to express this is in the language of linear algebra.\nSuppose we are given $p_0(x) = k_0$ (where $k_0 = 1$ is pretty much always the case in practice). This can be written in matrix form as\n$$\n(1,0,0,0,0,\\ldots) \\begin{pmatrix} p_0(x) \\cr p_1(x) \\cr p_2(x) \\cr \\vdots \\end{pmatrix} = k_0\n$$\nWe can combine this with the Jacobi operator to get\n$$\n\\underbrace{\\begin{pmatrix}\n1 \\\\\na_0-x & b_0 \\\\\nc_1 & a_1-x & b_1 \\\\\n& c_2 & a_2-x & b_2 \\cr\n&& c_3 & a_3-x & b_3 \\cr\n&&&\\ddots & \\ddots & \\ddots\n\\end{pmatrix}}_{L_x} \\begin{pmatrix} p_0(x) \\cr p_1(x) \\cr p_2(x) \\cr \\vdots \\end{pmatrix} = \\begin{pmatrix} k_0\\cr 0 \\cr 0 \\cr \\vdots \\end{pmatrix}\n$$\nFor $x$ fixed, this is a lower triangular system, that is, the polynomials equal\n$$\nk_0 L_x^{-1} \\vc e_0\n$$\nThis  can be solved  via forward recurrence:\n$$\n\\begin{align*}\n    p_0(x) &= k_0 \\\\\n    p_1(x) &= {(x-a_0) p_0(x) \\over b_0}\\\\\n    p_2(x) &= {(x-a_1) p_0(x) - c_1 p_0(x) \\over b_1}\\\\\n    p_3(x) &= {(x-a_2) p_1(x) - c_2 p_1(x) \\over b_2}\\\\\n    &\\vdots\n\\end{align*}\n$$\n\nWe can use this to evaluate functions as well:\n$$\nf(x) = (p_0(x),p_1(x),\\ldots) \\begin{pmatrix}f_0 \\\\ f_1\\\\ \\vdots \\end{pmatrix} =\nk_0 \\vc e_0^\\top L_x^{-\\top}  \\begin{pmatrix}f_0 \\\\ f_1\\\\ \\vdots \\end{pmatrix}\n$$\nwhen $f$ is a degree $n-1$ polynomial, this becomes a problem of inverting an upper triangular matrix,\nthat is, we want to solve the $n \\times n$ system\n$$\n\\underbrace{\\begin{pmatrix}\n1 & a_0-x & c_1 \\\\\n& b_0 & a_1-x & c_2  \\\\\n& & b_1 & a_2-x & \\ddots  \\\\\n& &     & b_2 & \\ddots & c_{n-2} \\\\\n&&&&\\ddots & a_{n-2}-x \\\\\n&&&&& b_{n-2}\n\\end{pmatrix}}_{L_x^\\top} \\begin{pmatrix} \\gamma_0 \\\\\\vdots\\\\ \\gamma_{n-1} \\end{pmatrix}\n$$\nso that $f(x)/k_0 = \\gamma_0$. We can solve this  via back-substitution:\n$$\n\\begin{align*}\n\\gamma_{n-1} &= {f_{n-1} \\over b_{n-2}} \\\\\n\\gamma_{n-2} &= {f_{n-2} - (a_{n-2}-x) \\gamma_{n-1} \\over b_{n-3}} \\\\\n\\gamma_{n-3} &= {f_{n-3} - (a_{n-3}-x) \\gamma_{n-2} - c_{n-2} \\gamma_{n-1} \\over b_{n-4}} \\\\\n& \\vdots \\\\\n\\gamma_1 &= {f_1 - (a_1-x) \\gamma_2 - c_2 \\gamma_3 \\over b_0} \\\\\n\\gamma_0 &= f_0 - (a_0-x) \\gamma_1 - c_1 \\gamma_2\n\\end{align*}\n$$\nWe give examples of these algorithms applied to Chebyshev polynomials in the next lecture.\n\n\n## Gram–Schmidt algorithm\n\nIn general we don't have nice formulae for OPs but we can always construct them via the Gram–Schmidt process:\n\n**Proposition (Gram–Schmidt)** Define\n$$\n\\begin{align*}\np_0(x) = 1 \\\\\nq_0(x) = {1 \\over \\norm{p_0}}\\\\\np_{n+1}(x) = x q_n(x) - \\sum_{k=0}^n \\ip<x q_n, q_k> q_k(x)\\\\\nq_{n+1}(x) = {p_{n+1}(x) \\over \\norm{p_{n+1}}}\n\\end{align*}\n$$\nThen $q_0(x), q_1(x), \\ldots$ are orthonormal w.r.t. $w$.\n\n**Proof** By linearity we have\n$$\n\\ip<p_{n+1}, q_j> = \\ip<x q_n - \\sum_{k=0}^n {\\ip<x q_n, q_k>} q_k, q_j> = \\ip<x q_n, q_j> - \\ip<x q_n, q_j> \\ip<q_j,q_j> = 0\n$$\nThus $p_{n+1}$ is orthogonal to all lower degree polynomials. So is $q_{n+1}$, since it is a constant multiple of $p_{n+1}$.\n\n■\n\nLet's make our own family of OPs:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using ApproxFun, Plots\nx = Fun()\nw = exp(x)\nip = (f,g) -> sum(f*g*w)\nnrm = f    -> sqrt(ip(f,f))\nn = 10\nq = Array{Fun}(undef,n)\np = Array{Fun}(undef,n)\np[1] = Fun(1, -1 .. 1 )\nq[1] = p[1]/nrm(p[1])\n\nfor k=1:n-1\n    p[k+1] = x*q[k]\n    for j=1:k\n        p[k+1] -= ip(p[k+1],q[j])*q[j]\n    end\n    q[k+1] = p[k+1]/nrm(p[k+1])\nend\n\n@show sum(q[2]*q[4]*w)\n\np = plot(; legend=false)\nfor k=1:10\n    plot!(q[k])\nend\np"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The three-term recurrence means we can simplify Gram--Schmidt, and calculate the recurrence coefficients at the same time:\n\n\n**Proposition (Gram–Schmidt)** Define\n$$\n\\begin{align*}\np_0(x) &= 1 \\\\\nq_0(x) &= {1 \\over \\norm{p_0}}\\\\\na_n &= \\ip<x q_n, q_n> \\\\\nb_{n-1} &= \\ip<x q_n, q_{n-1}>\\\\\np_{n+1}(x) &= x q_n(x) -  a_n q_n(x) -  b_{n-1} q_{n-1}(x)\\\\\nq_{n+1}(x) &= {p_{n+1}(x) \\over \\norm{p_{n+1}}}\n\\end{align*}\n$$\nThen $q_0(x), q_1(x), \\ldots$ are orthonormal w.r.t. $w$.\n\n**Remark** This can be made a bit more efficient by using $\\norm{p_{n+1}}$ to calculate $b_n$."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "x = Fun()\nw = exp(x)\nip = (f,g) -> sum(f*g*w)\nnrm = f    -> sqrt(ip(f,f))\nn = 10\nq = Array{Fun}(undef, n)\np = Array{Fun}(undef, n)\na = zeros(n)\nb = zeros(n)\np[1] = Fun(1, -1 .. 1 )\nq[1] = p[1]/nrm(p[1])\n\np[2] = x*q[1]\na[1] = ip(p[2],q[1])\np[2] -= a[1]*q[1]\nq[2] = p[2]/nrm(p[2])\n\nfor k=2:n-1\n    p[k+1] = x*q[k]\n    b[k-1] =ip(p[k+1],q[k-1])\n    a[k] = ip(p[k+1],q[k])\n    p[k+1] = p[k+1] - a[k]q[k] - b[k-1]q[k-1]\n    q[k+1] = p[k+1]/nrm(p[k+1])\nend\n\nip(q[5],q[2]) # shows orthogonality (to numerical accuracy)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see a plot of the first 10 polynomials:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "p = plot(; legend=false)\nfor k=1:10\n    plot!(q[k])\nend\np"
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.7.2"
    },
    "kernelspec": {
      "name": "julia-1.7",
      "display_name": "Julia 1.7.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
